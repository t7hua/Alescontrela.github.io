<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="XyWrmS0s13oZm3YGw5ruPZ8_SFL_MASFAkyTMdk-DkM"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>DayDreamer: World Models for Physical Robot Learning | Alejandro Escontrela</title> <meta name="author" content="Alejandro Escontrela"/> <meta name="description" content="Hyper data-efficient robot learning with world models"/> <meta name="keywords" content="AI, robotics, ML, artificial, intelligence, reinforcement, learning"/> <meta property="og:site_name" content="Alejandro Escontrela"/> <meta property="og:type" content="website"/> <meta property="og:title" content="Alejandro Escontrela | DayDreamer: World Models for Physical Robot Learning"/> <meta property="og:url" content="https://Alescontrela.github.io/projects/daydreamer/"/> <meta property="og:description" content="Hyper data-efficient robot learning with world models"/> <meta property="og:locale" content="en"/> <meta name="twitter:card" content="summary"/> <meta name="twitter:title" content="DayDreamer: World Models for Physical Robot Learning"/> <meta name="twitter:description" content="Hyper data-efficient robot learning with world models"/> <meta name="twitter:site" content="@aleescontrela"/> <meta name="twitter:creator" content="@aleescontrela"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://alescontrela.github.io/projects/daydreamer/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://Alescontrela.github.io/">Alejandro Escontrela</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">DayDreamer: World Models for Physical Robot Learning</h1> <p class="post-description">Hyper data-efficient robot learning with world models</p> </header> <article> <div class="row justify-content-sm-center"> <a href="https://www.dailymail.co.uk/sciencetech/article-11024615/Robot-dog-walk-ONE-hour-training-scientists-hope-play-fetch-future.html" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img style="padding: 5% 5% 5% 5%;" class="card-img border bg-white rounded" src="/assets/img/dailymail.png" alt="Card image cap"> </a> <a href="https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img style="padding: 5% 5% 5% 5%;" class="card-img border bg-white rounded" src="/assets/img/mittechreview.png" alt="Card image cap"> </a> <a href="https://techcrunch.com/2022/07/21/berkeley-shows-off-accelerated-learning-that-puts-robots-on-their-feet-in-minutes/" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img style="padding: 5% 5% 5% 5%;" class="card-img border bg-white rounded" src="/assets/img/techcrunch.png" alt="Card image cap"> </a> <a href="https://techxplore.com/news/2022-07-daydreamer-algorithm-quickly-robots-behaviors.html" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img class="card-img bg-white rounded" src="/assets/img/techxplore.png" alt="Card image cap"> </a> </div> <h2 id="authors">Authors</h2> <p><a href="https://twitter.com/philippswu" target="_blank" rel="noopener noreferrer">Philipp Wu</a>*, <a href="https://twitter.com/aleescontrela" target="_blank" rel="noopener noreferrer">Alejandro Escontrela</a>*, <a href="https://danijar.com/" target="_blank" rel="noopener noreferrer">Danijar Hafner</a>*, <a href="https://goldberg.berkeley.edu/" target="_blank" rel="noopener noreferrer">Ken Goldberg</a>, <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank" rel="noopener noreferrer">Pieter Abbeel</a> (* = equal authors)</p> <h2 id="publication-info">Publication info</h2> <div class="publications"> <ol class="bibliography"><li> <div class="card border-0"> <div class="row no-gutters"> <div class="col-sm-4 mx-auto my-auto"> <img src="/assets/img/daydreamer_splash.png" class="card-img mx-sm-2" style="max-width: 100%;"> </div> <div class="col-sm-8"> <div class="card-body"> <div id="Wu22CoRL_DayDreamer"> <div class="title"> <a href="https://arxiv.org/abs/2206.14176" target="_blank" rel="noopener noreferrer">Daydreamer: World Models for Physical Robot Learning</a> </div> <div class="author">Philipp Wu*, Alejandro Escontrela*, Danijar Hafner*, Ken Goldberg, and Pieter Abbeel </div> <div class="periodical"> <em>Proceedings of Machine Learning Research</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Wu22CoRL_DayDreamer.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/danijar/daydreamer" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/projects/daydreamer" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wu22CoRL_DayDreamer</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Daydreamer: World Models for Physical Robot Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Philipp and Escontrela*, Alejandro and Hafner*, Danijar and Goldberg, Ken and Abbeel, Pieter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </div> </div> </div> </li></ol> </div> <h2 id="learning-to-walk-in-the-real-world-in-under-an-hour">Learning to walk in the real world in under an hour</h2> <p>The A1 quadruped shown below learns to walk with DayDreamer in ~1 hour, from scratch, with no human intervention.</p> <p style="position: relative; text-align: center; height: 0; padding-bottom: 56.25%; margin-bottom: 0;"> <iframe frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; margin-bottom: -.5em" src="https://www.youtube-nocookie.com/embed/xAXvfVTgqr0?rel=0" allowfullscreen=""></iframe> </p> <p><br></p> <div class="row"> <div class="text-center col-3 col-sm-3 mt-3 mt-md-0"> <h4><a href="https://arxiv.org/pdf/2206.14176.pdf" target="_blank" rel="noopener noreferrer">Paper</a></h4> </div> <div class="text-center col-3 col-sm-3 mt-3 mt-md-0"> <h4><a href="https://twitter.com/danijarh/status/1542170248706609152" target="_blank" rel="noopener noreferrer">Twitter</a></h4> </div> <div class="text-center col-3 col-sm-3 mt-3 mt-md-0"> <h4><a href="https://www.youtube.com/watch?v=A6Rg0qRwTYs" target="_blank" rel="noopener noreferrer">Talk</a></h4> </div> <div class="text-center col-3 col-sm-3 mt-3 mt-md-0"> <h4><a href="https://github.com/danijar/daydreamer" target="_blank" rel="noopener noreferrer">Code</a></h4> </div> </div> <p><br></p> <h2 id="abstract">Abstract</h2> <p>To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without any simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, which establishes a strong baseline. We release our infrastructure for future applications of world models to robot learning.</p> <h2 id="robots">Robots</h2> <div class="card-deck"> <div class="card"> <img class="card-img-top" src="/assets/gif/1_a1.gif" alt="Card image cap"> <div class="card-body"> <h5 class="card-title text-center">A1 Quadruped Walking</h5> </div> </div> <div class="card"> <img class="card-img-top" src="/assets/gif/2_ur5.gif" alt="Card image cap"> <div class="card-body"> <h5 class="card-title text-center">UR5 Multi-Object Visual Pick Place</h5> </div> </div> <div class="card"> <img class="card-img-top" src="/assets/gif/3_xarm.gif" alt="Card image cap"> <div class="card-body"> <h5 class="card-title text-center">XArm Visual Pick and Place</h5> </div> </div> <div class="card"> <img class="card-img-top" src="/assets/gif/4_sphero.gif" alt="Card image cap"> <div class="card-body"> <h5 class="card-title text-center">Sphero Ollie Visual Navigation</h5> </div> </div> </div> <p><br></p> <h2 id="all-media-coverage">All Media Coverage</h2> <ul> <li><a href="https://www.dailymail.co.uk/sciencetech/article-11024615/Robot-dog-walk-ONE-hour-training-scientists-hope-play-fetch-future.html" target="_blank" rel="noopener noreferrer">Daily Mail</a></li> <li><a href="https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/" target="_blank" rel="noopener noreferrer">MIT Technology Review</a></li> <li> <a href="https://techcrunch.com/2022/07/21/berkeley-shows-off-accelerated-learning-that-puts-robots-on-their-feet-in-minutes/" target="_blank" rel="noopener noreferrer">TechCrunch</a> (<a href="https://www.youtube.com/watch?v=h8AUJwPdTIE" target="_blank" rel="noopener noreferrer">Video</a>)</li> <li><a href="https://syncedreview.com/2022/07/04/learning-without-simulations-uc-berkeleys-daydreamer-establishes-a-strong-baseline-for-real-world-robotic-training/" target="_blank" rel="noopener noreferrer">Synced</a></li> <li><a href="https://singularityhub.com/2022/08/08/this-robot-dog-has-an-ai-brain-and-taught-itself-to-walk-in-just-an-hour/" target="_blank" rel="noopener noreferrer">SingularityHub</a></li> <li><a href="https://www.zmescience.com/science/robot-teaches-itself-to-walk-235242/" target="_blank" rel="noopener noreferrer">ZME Science</a></li> <li><a href="https://www.technology.org/2022/06/29/daydreamer-world-models-for-physical-robot-learning/" target="_blank" rel="noopener noreferrer">Technology Org</a></li> <li><a href="https://www.indiatimes.com/technology/science-and-future/robot-dog-taught-itself-how-to-walk-575118.html" target="_blank" rel="noopener noreferrer">India Times</a></li> <li><a href="https://analyticsindiamag.com/this-robot-used-dreamer-algorithm-to-learn-walking-in-60-minutes/" target="_blank" rel="noopener noreferrer">Analytics India Mag (AIM)</a></li> <li><a href="https://www.marktechpost.com/2022/07/05/uc-berkeley-researchers-use-a-dreamer-world-model-to-train-a-variety-of-real-world-robots-to-learn-from-experience/" target="_blank" rel="noopener noreferrer">MarkTechPost</a></li> <li><a href="https://news7g.com/daydreamer-world-model-for-learning-robot-physics/" target="_blank" rel="noopener noreferrer">NEWS7g</a></li> <li><a href="https://www.actuia.com/actualite/daydreamer-former-les-robots-dans-le-monde-reel-grace-a-lapprentissage-par-renforcement-en-ligne/" target="_blank" rel="noopener noreferrer">ActuIA</a></li> <li><a href="https://www.i-programmer.info/news/105-artificial-intelligence/15646-robot-dog-from-rolling-on-floor-to-walking-in-1-hour.html" target="_blank" rel="noopener noreferrer">I Programmer</a></li> <li><a href="https://engineering.berkeley.edu/news/2022/10/step-by-step/" target="_blank" rel="noopener noreferrer">Berkeley Engineering</a></li> </ul> <h2 id="acknowledgements">Acknowledgements</h2> <p>We thank <a href="https://stepjam.github.io/" target="_blank" rel="noopener noreferrer">Stephen James</a> and <a href="https://kerrj.github.io/" target="_blank" rel="noopener noreferrer">Justin Kerr</a> for helpful suggestions and help with printing the protective shell of the quadruped robot. We thank <a href="https://www.linkedin.com/in/ademi-adeniji" target="_blank" rel="noopener noreferrer">Ademi Adeniji</a> for help with setting up the XArm robot and <a href="https://twitter.com/ravenhuang4?lang=en" target="_blank" rel="noopener noreferrer">Raven Huang</a> for help with setting up the UR5 robot. This work was supported in part by an NSF Fellowship, NSF NRI #2024675, and the Vanier Canada Graduate Scholarship.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Alejandro Escontrela. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_bib.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0LS8VY9HJQ"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0LS8VY9HJQ");</script> <script async src="https://cdn.panelbear.com/analytics.js?site=7HZ7BpCMplt"></script> <script>window.panelbear=window.panelbear||function(){(window.panelbear.q=window.panelbear.q||[]).push(arguments)},panelbear("config",{site:"7HZ7BpCMplt"});</script> </body> </html>