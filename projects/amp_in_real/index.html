<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="XyWrmS0s13oZm3YGw5ruPZ8_SFL_MASFAkyTMdk-DkM"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions | Alejandro Escontrela</title> <meta name="author" content="Alejandro Escontrela"/> <meta name="description" content="Using motion priors to learn energy-efficient and natural robot locomotion strategies"/> <meta name="keywords" content="AI, robotics, ML, artificial, intelligence, reinforcement, learning"/> <meta property="og:site_name" content="Alejandro Escontrela"/> <meta property="og:type" content="website"/> <meta property="og:title" content="Alejandro Escontrela | Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions"/> <meta property="og:url" content="https://Alescontrela.github.io/projects/amp_in_real/"/> <meta property="og:description" content="Using motion priors to learn energy-efficient and natural robot locomotion strategies"/> <meta property="og:locale" content="en"/> <meta name="twitter:card" content="summary"/> <meta name="twitter:title" content="Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions"/> <meta name="twitter:description" content="Using motion priors to learn energy-efficient and natural robot locomotion strategies"/> <meta name="twitter:site" content="@aleescontrela"/> <meta name="twitter:creator" content="@aleescontrela"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://alescontrela.github.io/projects/amp_in_real/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://Alescontrela.github.io/">Alejandro Escontrela</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions</h1> <p class="post-description">Using motion priors to learn energy-efficient and natural robot locomotion strategies</p> </header> <article> <div class="row justify-content-sm-center"> <a href="https://techcrunch.com/2022/07/21/berkeley-shows-off-accelerated-learning-that-puts-robots-on-their-feet-in-minutes/" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img style="padding: 5% 5% 5% 5%;" class="card-img border bg-white rounded" src="/assets/img/techcrunch.png" alt="Card image cap"> </a> <a href="https://www.youtube.com/watch?v=h8AUJwPdTIE&amp;t=1s" class="col-6 col-sm-6 col-md-3 mt-3 mt-md-0" target="_blank" rel="noopener noreferrer"> <img style="padding: 5% 5% 5% 5%; background: linear-gradient(90deg, rgba(18,70,29,1) 0%, rgba(16,92,28,1) 100%) !important;" class="card-img bg-white rounded" src="/assets/img/techcrunch_robotics.png" alt="Card image cap"> </a> </div> <h2 id="authors">Authors</h2> <p><a href="https://twitter.com/aleescontrela" target="_blank" rel="noopener noreferrer">Alejandro Escontrela</a>, <a href="https://xbpeng.github.io/" target="_blank" rel="noopener noreferrer">Xue Bin Peng</a>, <a href="https://research.google/people/107213/" target="_blank" rel="noopener noreferrer">Wenhao Yu</a>, <a href="https://research.google/people/TingnanZhang/" target="_blank" rel="noopener noreferrer">Tingnan Zhang</a>, <a href="https://www.linkedin.com/in/atil-iscen-32737945" target="_blank" rel="noopener noreferrer">Atil Iscen</a>, <a href="https://goldberg.berkeley.edu/" target="_blank" rel="noopener noreferrer">Ken Goldberg</a>, <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank" rel="noopener noreferrer">Pieter Abbeel</a></p> <h2 id="publication-info">Publication info</h2> <div class="publications"> <ol class="bibliography"><li> <div class="card border-0"> <div class="row no-gutters"> <div class="col-sm-4 mx-auto my-auto"> <img src="/assets/img/adversarial_motion_priors.png" class="card-img mx-sm-2" style="max-width: 100%;"> </div> <div class="col-sm-8"> <div class="card-body"> <div id="Escontrela22arXiv_AMP_in_real"> <div class="title"> <a href="https://arxiv.org/abs/2203.15103" target="_blank" rel="noopener noreferrer">Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions</a> </div> <div class="author"> <em>Alejandro Escontrela</em>, Xue Bin Peng, Wenhao Yu, Tingnan Zhang, Atil Iscen, Ken Goldberg, and Pieter Abbeel </div> <div class="periodical"> <em>International Conference on Intelligent Robots and Systems</em> 2022 </div> <div class="award"> <b><em><a href="https://iros2022.org/2022/10/30/award-winners/" target="_blank" rel="noopener noreferrer">Best Paper Award finalist</a>, <p style="color: red; display: inline;">(0.6%)</p></em></b> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Escontrela22IROS_amp_in_real.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/Alescontrela/AMP_for_hardware" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/projects/amp_in_real" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Escontrela22arXiv_AMP_in_real</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/ARXIV.2203.15103}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Escontrela, Alejandro and Peng, Xue Bin and Yu, Wenhao and Zhang, Tingnan and Iscen, Atil and Goldberg, Ken and Abbeel, Pieter}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Artificial Intelligence (cs.AI), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Creative Commons Attribution 4.0 International}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </div> </div> </div> </li></ol> </div> <h2 id="leveraging-adversarial-motion-priors-for-robot-locomotion">Leveraging adversarial motion priors for robot locomotion</h2> <p style="position: relative; text-align: center; height: 0; padding-bottom: 56.25%; margin-bottom: 0;"> <iframe frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; margin-bottom: -.5em" src="https://www.youtube.com/embed/Bo88rwUQbrM?rel=0" allowfullscreen=""></iframe> </p> <p><br></p> <div class="row"> <div class="text-center col-4 col-sm-4 mt-4 mt-md-0"> <h4><a href="https://arxiv.org/pdf/2203.15103.pdf" target="_blank" rel="noopener noreferrer">Paper</a></h4> </div> <div class="text-center col-4 col-sm-4 mt-4 mt-md-0"> <h4><a href="https://twitter.com/AleEscontrela/status/1509244950529118210?s=20&amp;t=A6gMqJaCywunW8bj2h0qHw" target="_blank" rel="noopener noreferrer">Twitter</a></h4> </div> <div class="text-center col-4 col-sm-4 mt-4 mt-md-0"> <h4><a href="https://github.com/Alescontrela/AMP_for_hardware" target="_blank" rel="noopener noreferrer">Code</a></h4> </div> </div> <p><br></p> <h2 id="overview">Overview</h2> <div class="row"> <div class="text col-12 col-sm-12 col-md-6 mt-4 mt-md-0"> <p>We propose substituting complex reward functions with motion priors learned from a dataset of motion capture demonstrations. A learned style reward can be combined with an arbitrary task reward to train policies that perform tasks using naturalistic strategies. These natural strategies can also facilitate transfer to the real world. We build upon Adversarial Motion Priors - an approach from the computer graphics domain that encodes a style reward from a dataset of reference motions - to demonstrate that an adversarial approach to training policies can produce behaviors that transfer to a real quadrupedal robot without requiring complex reward functions. We also demonstrate that an effective style reward can be learned from a few seconds of motion capture data gathered from a German Shepherd and leads to energy-efficient locomotion strategies with natural gait transitions.</p> </div> <div class="text-center col-12 col-sm-12 col-md-6 mt-4 mt-md-0"> <img class="card-img-top" src="/assets/img/amp_arch.png" alt="Card image cap"> </div> </div> <h2 id="example-behaviors">Example behaviors</h2> <div class="row"> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/lhji1NY1-d4" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> </div> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/oJm77Gz5PR8" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> </div> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/PRcNXRMhVWs" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> </div> </div> <p><br></p> <h2 id="energy-efficiency-comparison-with-baselines">Energy efficiency comparison with baselines</h2> <div class="row"> <div class="text col-12"> <p> We estimate the Cost of Transport (COT) for a policy trained using Adversarial Motion Priors. COT is a dimensionless quantity commonly used in the field of legged locomotion, as it allows for energy-efficiency comparisons of dissimilar robots or controllers. We utilize the COT to measure the efficiency of different baselines at different speeds. </p> <p> A policy trained using AMP successfully tracks the desired forward velocity commands while exhibiting a lower COT than competing baselines (see paper). The energy efficiency of policies trained with AMP can likely be attributed to the policy extracting energy-efficient motion priors from the reference data. Millions of years of evolution has endowed dogs with energy-efficient locomotion behaviors. Training with AMP enables the policy to extract some of these energy-efficient strategies from the data. Additionally, animals often perform gait transitions when undergoing large changes in velocity, lowering the cost of transport across different speeds. The same principle applies to policies trained using AMP. The below figure demonstrates the robot transitioning from a pacing motion to a canter motion when the desired velocity jumps from 1 m/s to 2 m/s. While pacing is the optimal gait at low speeds, entering a canter motion with a flight phase is a more energy-efficient option at high speeds. </p> </div> <div class="text col-12"> <img class="card-img-top" src="/assets/img/cot_diagram.png" alt="Card image cap"> </div> </div> <h2 id="motion-priors-substitute-the-need-for-complex-style-rewards-or-custom-action-spaces">Motion priors substitute the need for complex style rewards or custom action spaces</h2> <div class="row"> <div class="text-center col-12 col-sm-12 col-md-5 mt-4 mt-md-0"> <img class="card-img-top" src="/assets/img/amp_csr_or_cas.png" alt="Card image cap"> </div> <div class="text col-12 col-sm-12 col-md-7 mt-4 mt-md-0"> <p>Complex reward functions with tens of terms or custom action spaces are normally used to ensure that policies transfer from simulation to reality. The terms in the complex reward function are often used to disincentivize the policy from learning behaviors which exploit the inaccurate simulation dynamics or are inefficient. While policies trained in this manner transfer to hardware, it is often tedious to hand-design giant reward functions and weight their individual components. Additionally, these hand-designed reward functions are often platform-dependent and don't work well across all tasks. Alternatively, researchers have explored defining custom action spaces such as trajectory generators. These hand-defined action spaces prevent the robot from learning undesired behaviors, but often limit the performance of the resulting policy and require significant engineering effort to develop. Adversarial Motion Priors provide a promising alternative to these approaches. Using a small amount of reference data, we can learn a style reward that encourages the agent to learn efficient and aesthetically pleasing behaviors with minimal engineering effort.</p> </div> </div> <h2 id="more-behaviors">More behaviors</h2> <div class="row"> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/mPhKhn8VBgQ" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> <div class="text-center"><p>Informal race between <a href="https://arxiv.org/pdf/2111.01674.pdf" target="_blank" rel="noopener noreferrer">Fu et al.</a> (left) and AMP Policy (right)</p></div> </div> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/xR13j7gVYro" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> <div class="text-center"><p>A user can use a joystick policy to provide the policy with command velocities. The AMP controller produces precise behaviors which enable the robot to navigate a course with tight turns.</p></div> </div> <div class="text col-12 col-sm-12 col-md-4"> <div class="embed-responsive embed-responsive-1by1"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/hbTpjwsKZQs" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> <div class="text-center"><p>AMP policy performing a figure eight maneuver, which requires interpolating within a range of angular velocities.</p></div> </div> </div> <p><br></p> <h2 id="acknowledgements">Acknowledgements</h2> <p>The authors would like to thank <a href="https://www.lauvisuals.com/" target="_blank" rel="noopener noreferrer">Adam Lau</a>, <a href="https://kerrj.github.io/" target="_blank" rel="noopener noreferrer">Justin Kerr</a>, <a href="https://www.ipr.kit.edu/english/staff_2970.php" target="_blank" rel="noopener noreferrer">Lars Berscheid</a>, and <a href="https://twitter.com/chungminkim?lang=en" target="_blank" rel="noopener noreferrer">Chung Min Kim</a> for their helpful contributions and discussions.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Alejandro Escontrela. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_bib.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0LS8VY9HJQ"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0LS8VY9HJQ");</script> <script async src="https://cdn.panelbear.com/analytics.js?site=7HZ7BpCMplt"></script> <script>window.panelbear=window.panelbear||function(){(window.panelbear.q=window.panelbear.q||[]).push(arguments)},panelbear("config",{site:"7HZ7BpCMplt"});</script> </body> </html>